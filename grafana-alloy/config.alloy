// Grafana Alloy Configuration for OpenTelemetry Collection
// 
// Architecture:
// 1. Application telemetry (traces/metrics/logs) → OTLP Gateway → Tempo/Mimir/Loki
// 2. Infrastructure metrics (PostgreSQL/Redis/RabbitMQ) → OTEL processors → OTLP Gateway → Mimir
// 3. All metrics have service.name resource attribute for consistent filtering
//
// Key Learning: All metrics routed through OTLP for unified resource attributes

// ========================================
// Logging Configuration
// ========================================
// Alloy self-monitoring: Export logs to Grafana Cloud Loki
// Log level configurable via ALLOY_LOG_LEVEL environment variable
logging {
  level    = coalesce(env("ALLOY_LOG_LEVEL"), "info")
  format   = "json"
  write_to = [loki.write.grafana_cloud_loki.receiver]
}

loki.write "grafana_cloud_loki" {
  endpoint {
    url = env("GRAFANA_CLOUD_LOKI_ENDPOINT")
    basic_auth {
      username = env("GRAFANA_CLOUD_LOKI_INSTANCE_ID")
      password = env("GRAFANA_CLOUD_API_KEY")
    }
  }
}

// ========================================
// Docker Log Collection
// ========================================
// Collect logs from all Docker containers with 'service' label

discovery.docker "containers" {
  host = "unix:///var/run/docker.sock"
  
  filter {
    name   = "label"
    values = ["service"]
  }
}

loki.source.docker "containers" {
  host             = "unix:///var/run/docker.sock"
  targets          = discovery.docker.containers.targets
  forward_to       = [loki.process.add_static_labels.receiver]
  refresh_interval = "5s"
}

loki.process "add_static_labels" {
  forward_to = [loki.write.grafana_cloud_loki.receiver]
  
  stage.docker {}
  
  stage.labels {
    values = {
      service     = "",
      environment = "",
      container   = "",
    }
  }
}

// ========================================
// OTLP Receiver - Application Telemetry
// ========================================
// Receives traces, metrics, and logs from instrumented Python services

otelcol.receiver.otlp "default" {
  grpc {
    endpoint = "0.0.0.0:4317"
  }

  http {
    endpoint = "0.0.0.0:4318"
  }

  output {
    traces  = [otelcol.processor.batch.default.input]
    metrics = [otelcol.processor.batch.default.input]
    logs    = [otelcol.processor.batch.default.input]
  }
}

// ========================================
// Batch Processor
// ========================================
// Batches telemetry for efficient export (default 10s timeout)

otelcol.processor.batch "default" {
  timeout = "10s"

  output {
    traces  = [otelcol.exporter.otlphttp.grafana_cloud_otlp.input]
    metrics = [otelcol.exporter.otlphttp.grafana_cloud_otlp.input]
    logs    = [otelcol.exporter.otlphttp.grafana_cloud_otlp.input]
  }
}

// ========================================
// OTLP Gateway Authentication
// ========================================
// Instance ID for OTLP Gateway (not Prometheus!)
// This single gateway routes all three signal types to their backends

otelcol.auth.basic "grafana_cloud_otlp" {
  username = env("GRAFANA_CLOUD_OTLP_INSTANCE_ID")
  password = env("GRAFANA_CLOUD_API_KEY")
}

// ========================================
// OTLP HTTP Exporter - Unified Application Telemetry
// ========================================
// Single exporter handles all application signals via HTTP/protobuf:
// - Traces → Tempo
// - Metrics → Mimir  
// - Logs → Loki

otelcol.exporter.otlphttp "grafana_cloud_otlp" {
  client {
    endpoint = env("GRAFANA_CLOUD_OTLP_ENDPOINT")
    auth     = otelcol.auth.basic.grafana_cloud_otlp.handler
  }
}

// ========================================
// PostgreSQL Metrics - Infrastructure Monitoring
// ========================================
// Uses built-in postgres_exporter with reasonable defaults
// High-cardinality collectors (stat_statements, per-table stats) disabled by default

prometheus.exporter.postgres "integrations_postgres_exporter" {
  data_source_names = [format("postgresql://%s:%s@postgres:5432/%s?sslmode=disable", env("POSTGRES_USER"), env("POSTGRES_PASSWORD"), env("POSTGRES_DB"))]
}

discovery.relabel "integrations_postgres_exporter" {
  targets = prometheus.exporter.postgres.integrations_postgres_exporter.targets

  rule {
    target_label = "job"
    replacement  = "integrations/postgres_exporter"
  }
  rule {
    target_label = "instance"
    replacement  = "postgres"
  }
}

prometheus.scrape "integrations_postgres_exporter" {
  targets         = discovery.relabel.integrations_postgres_exporter.output
  forward_to      = [otelcol.receiver.prometheus.postgres_metrics.receiver]
  job_name        = "integrations/postgres_exporter"
  scrape_interval = "60s"
}

otelcol.receiver.prometheus "postgres_metrics" {
  output {
    metrics = [otelcol.processor.resource.add_service_name_postgres.input]
  }
}

otelcol.processor.resource "add_service_name_postgres" {
  attributes {
    insert {
      key   = "service.name"
      value = "postgres"
    }
  }
  output {
    metrics = [otelcol.processor.batch.default.input]
  }
}

// ========================================
// Redis Metrics - Infrastructure Monitoring
// ========================================
// Uses built-in redis_exporter with default configuration
// High-cardinality options (client_list, per-key stats) disabled by default

prometheus.exporter.redis "integrations_redis_exporter" {
  redis_addr = "redis:6379"
}

prometheus.scrape "integrations_redis_exporter" {
  targets         = prometheus.exporter.redis.integrations_redis_exporter.targets
  forward_to      = [otelcol.receiver.prometheus.redis_metrics.receiver]
  job_name        = "integrations/redis_exporter"
  scrape_interval = "60s"
}

otelcol.receiver.prometheus "redis_metrics" {
  output {
    metrics = [otelcol.processor.resource.add_service_name_redis.input]
  }
}

otelcol.processor.resource "add_service_name_redis" {
  attributes {
    insert {
      key   = "service.name"
      value = "redis"
    }
  }
  output {
    metrics = [otelcol.processor.batch.default.input]
  }
}

// ========================================
// RabbitMQ Metrics - Infrastructure Monitoring
// ========================================
// Scrapes RabbitMQ's built-in Prometheus endpoint
// Per-object metrics enabled via rabbitmq.conf for queue-level visibility

prometheus.scrape "integrations_rabbitmq" {
  targets = [{
    __address__ = "rabbitmq:15692",
    job         = "integrations/rabbitmq",
    instance    = "rabbitmq",
  }]
  forward_to      = [otelcol.receiver.prometheus.rabbitmq_metrics.receiver]
  scrape_interval = "60s"
}

otelcol.receiver.prometheus "rabbitmq_metrics" {
  output {
    metrics = [otelcol.processor.resource.add_service_name_rabbitmq.input]
  }
}

otelcol.processor.resource "add_service_name_rabbitmq" {
  attributes {
    insert {
      key   = "service.name"
      value = "rabbitmq"
    }
  }
  output {
    metrics = [otelcol.processor.batch.default.input]
  }
}

// ========================================
// Alloy Self-Monitoring - Metrics
// ========================================
// Export Alloy's internal metrics for operational visibility

prometheus.exporter.self "default" {
}

prometheus.scrape "alloy_self" {
  targets         = prometheus.exporter.self.default.targets
  forward_to      = [otelcol.receiver.prometheus.alloy_metrics.receiver]
  job_name        = "alloy/self-monitoring"
  scrape_interval = "60s"
}

otelcol.receiver.prometheus "alloy_metrics" {
  output {
    metrics = [otelcol.exporter.otlphttp.grafana_cloud_otlp.input]
  }
}

// ========================================
// Alloy Self-Monitoring - Traces
// ========================================
// Export Alloy's internal traces for operational visibility
tracing {
  sampling_fraction = 1.0
  write_to          = [otelcol.exporter.otlphttp.grafana_cloud_otlp.input]
}

// ========================================
// Infrastructure Metrics Processing
// ========================================
// All metrics (application + infrastructure) now route through OTLP
// with service.name resource attributes for consistent filtering
