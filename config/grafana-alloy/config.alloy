// Grafana Alloy Configuration for OpenTelemetry Collection
//
// Architecture:
// 1. Application telemetry (traces/metrics/logs) → OTLP Gateway → Tempo/Mimir/Loki
// 2. Infrastructure metrics (PostgreSQL/Redis/RabbitMQ) → Prometheus → OTEL batch → Mimir
// 3. Metrics identified by job and instance labels for filtering
//
// Key Learning: Infrastructure metrics routed through OTLP batch processor for efficiency

// ========================================
// Logging Configuration
// ========================================
// Alloy self-monitoring: Export logs to Grafana Cloud Loki
// Log level configurable via ALLOY_LOG_LEVEL environment variable
logging {
  level    = coalesce(env("ALLOY_LOG_LEVEL"), "info")
  format   = "json"
  write_to = [loki.process.alloy_logs.receiver]
}

loki.process "alloy_logs" {
  forward_to = [loki.write.grafana_cloud_loki.receiver]

  stage.static_labels {
    values = {
      service     = "grafana-alloy",
      environment = coalesce(env("ENVIRONMENT"), "production"),
    }
  }
}

loki.write "grafana_cloud_loki" {
  endpoint {
    url = env("GRAFANA_CLOUD_LOKI_ENDPOINT")
    basic_auth {
      username = env("GRAFANA_CLOUD_LOKI_INSTANCE_ID")
      password = env("GRAFANA_CLOUD_API_KEY")
    }
  }
}

// ========================================
// Docker Log Collection
// ========================================
// Collect logs from infrastructure services only (postgres, rabbitmq, redis, grafana-alloy, frontend)
// Application services (api, bot, init, daemons) send logs via OTLP to avoid duplication
// NOTE: New services must be explicitly added here to be collected

discovery.docker "containers" {
  host = "unix:///var/run/docker.sock"

  // Collect all containers with service label
  filter {
    name   = "label"
    values = ["service"]
  }
}

discovery.relabel "docker_labels" {
  targets = discovery.docker.containers.targets

  // Keep only infrastructure services (drop application services that use OTLP)
  rule {
    source_labels = ["__meta_docker_container_label_service"]
    regex         = "postgres|rabbitmq|redis|grafana-alloy|frontend"
    action        = "keep"
  }

  rule {
    source_labels = ["__meta_docker_container_label_service"]
    target_label  = "service"
  }

  rule {
    source_labels = ["__meta_docker_container_label_environment"]
    target_label  = "environment"
  }

  rule {
    source_labels = ["__meta_docker_container_name"]
    target_label  = "container"
  }
}

loki.source.docker "containers" {
  host             = "unix:///var/run/docker.sock"
  targets          = discovery.relabel.docker_labels.output
  forward_to       = [loki.process.add_container_labels.receiver]
  refresh_interval = "5s"
}

loki.process "add_container_labels" {
  forward_to = [loki.write.grafana_cloud_loki.receiver]

  stage.docker {}

  stage.labels {
    values = {
      service     = "",
      environment = "",
      container   = "",
    }
  }
}

// ========================================
// OTLP Receiver - Application Telemetry
// ========================================
// Receives traces, metrics, and logs from instrumented Python services

otelcol.receiver.otlp "default" {
  grpc {
    endpoint = "0.0.0.0:4317"
  }

  http {
    endpoint = "0.0.0.0:4318"
  }

  output {
    traces  = [otelcol.processor.batch.default.input]
    metrics = [otelcol.processor.batch.default.input]
    logs    = [otelcol.processor.batch.default.input]
  }
}

// ========================================
// Batch Processor
// ========================================
// Batches telemetry for efficient export (default 10s timeout)

otelcol.processor.batch "default" {
  timeout = "10s"

  output {
    traces  = [otelcol.exporter.otlphttp.grafana_cloud_otlp.input]
    metrics = [otelcol.exporter.otlphttp.grafana_cloud_otlp.input]
    logs    = [otelcol.exporter.otlphttp.grafana_cloud_otlp.input]
  }
}

// ========================================
// OTLP Gateway Authentication
// ========================================
// Instance ID for OTLP Gateway (not Prometheus!)
// This single gateway routes all three signal types to their backends

otelcol.auth.basic "grafana_cloud_otlp" {
  username = env("GRAFANA_CLOUD_OTLP_INSTANCE_ID")
  password = env("GRAFANA_CLOUD_API_KEY")
}

// ========================================
// OTLP HTTP Exporter - Unified Application Telemetry
// ========================================
// Single exporter handles all application signals via HTTP/protobuf:
// - Traces → Tempo
// - Metrics → Mimir
// - Logs → Loki

otelcol.exporter.otlphttp "grafana_cloud_otlp" {
  client {
    endpoint = env("GRAFANA_CLOUD_OTLP_ENDPOINT")
    auth     = otelcol.auth.basic.grafana_cloud_otlp.handler
  }
}

// ========================================
// PostgreSQL Metrics - Infrastructure Monitoring
// ========================================
// Uses built-in postgres_exporter with reasonable defaults
// High-cardinality collectors (stat_statements, per-table stats) disabled by default

prometheus.exporter.postgres "integrations_postgres_exporter" {
  data_source_names = [format("postgresql://%s:%s@postgres:5432/%s?sslmode=disable", env("POSTGRES_USER"), env("POSTGRES_PASSWORD"), env("POSTGRES_DB"))]
}

discovery.relabel "integrations_postgres_exporter" {
  targets = prometheus.exporter.postgres.integrations_postgres_exporter.targets

  rule {
    target_label = "job"
    replacement  = "integrations/postgres_exporter"
  }
  rule {
    target_label = "instance"
    replacement  = "postgres"
  }
}

prometheus.scrape "integrations_postgres_exporter" {
  targets         = discovery.relabel.integrations_postgres_exporter.output
  forward_to      = [otelcol.receiver.prometheus.postgres_metrics.receiver]
  job_name        = "integrations/postgres_exporter"
  scrape_interval = "60s"
}

otelcol.receiver.prometheus "postgres_metrics" {
  output {
    metrics = [otelcol.processor.batch.default.input]
  }
}

// ========================================
// Redis Metrics - Infrastructure Monitoring
// ========================================
// Uses built-in redis_exporter with default configuration
// High-cardinality options (client_list, per-key stats) disabled by default

prometheus.exporter.redis "integrations_redis_exporter" {
  redis_addr = "redis:6379"
}

prometheus.scrape "integrations_redis_exporter" {
  targets         = prometheus.exporter.redis.integrations_redis_exporter.targets
  forward_to      = [otelcol.receiver.prometheus.redis_metrics.receiver]
  job_name        = "integrations/redis_exporter"
  scrape_interval = "60s"
}

otelcol.receiver.prometheus "redis_metrics" {
  output {
    metrics = [otelcol.processor.batch.default.input]
  }
}

// ========================================
// RabbitMQ Metrics - Infrastructure Monitoring
// ========================================
// Scrapes RabbitMQ's built-in Prometheus endpoint
// Per-object metrics enabled via rabbitmq.conf for queue-level visibility

prometheus.scrape "integrations_rabbitmq" {
  targets = [{
    __address__ = "rabbitmq:15692",
    job         = "integrations/rabbitmq",
    instance    = "rabbitmq",
  }]
  forward_to      = [otelcol.receiver.prometheus.rabbitmq_metrics.receiver]
  scrape_interval = "60s"
}

otelcol.receiver.prometheus "rabbitmq_metrics" {
  output {
    metrics = [otelcol.processor.batch.default.input]
  }
}

// ========================================
// Alloy Self-Monitoring - Metrics
// ========================================
// Export Alloy's internal metrics for operational visibility

prometheus.exporter.self "default" {
}

prometheus.scrape "alloy_self" {
  targets         = prometheus.exporter.self.default.targets
  forward_to      = [otelcol.receiver.prometheus.alloy_metrics.receiver]
  job_name        = "alloy/self-monitoring"
  scrape_interval = "60s"
}

otelcol.receiver.prometheus "alloy_metrics" {
  output {
    metrics = [otelcol.processor.attributes.alloy_metrics.input]
  }
}

otelcol.processor.attributes "alloy_metrics" {
  action {
    key    = "service.name"
    value  = "grafana-alloy"
    action = "insert"
  }

  output {
    metrics = [otelcol.processor.batch.default.input]
  }
}

// ========================================
// Alloy Self-Monitoring - Traces
// ========================================
// Export Alloy's internal traces for operational visibility
tracing {
  sampling_fraction = 1.0
  write_to          = [otelcol.processor.attributes.alloy_traces.input]
}

otelcol.processor.attributes "alloy_traces" {
  action {
    key    = "service.name"
    value  = "grafana-alloy"
    action = "insert"
  }

  output {
    traces = [otelcol.processor.batch.default.input]
  }
}

// ========================================
// Infrastructure Metrics Processing
// ========================================
// All metrics (application + infrastructure) now route through OTLP
// with service.name resource attributes for consistent filtering
